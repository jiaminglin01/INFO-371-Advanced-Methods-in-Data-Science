{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Creating an Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.array([[1.0,0,2,0,4,3],[3,0,1,1,0,0],[2,0,4,0,1,0],\n",
    "              [0,0,1,0,0,1],[8,0,3,0,5,2],[0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Modifying the Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Zii equal to 0\n",
    "for i in range(len(Z)):\n",
    "    Z[i,i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 2., 0., 4., 3.],\n",
       "       [3., 0., 1., 1., 0., 0.],\n",
       "       [2., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 1.],\n",
       "       [8., 0., 3., 0., 0., 2.],\n",
       "       [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "H = Z.copy()\n",
    "for i in range(len(H[0])):\n",
    "    col_sum = 0\n",
    "    for j in range(len(H)):\n",
    "        col_sum = col_sum + H[j,i]\n",
    "    if col_sum != 0:\n",
    "        for k in range(len(H)):\n",
    "            H[k,i] = H[k,i]/col_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.28571429, 0.        , 0.8       ,\n",
       "        0.5       ],\n",
       "       [0.23076923, 0.        , 0.14285714, 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.15384615, 0.        , 0.        , 0.        , 0.2       ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.14285714, 0.        , 0.        ,\n",
       "        0.16666667],\n",
       "       [0.61538462, 0.        , 0.42857143, 0.        , 0.        ,\n",
       "        0.33333333],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Identifying the Dangling Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.zeros(len(H[0]))\n",
    "for i in range(len(H[0])):\n",
    "    col_sum = 0\n",
    "    for j in range(len(H)):\n",
    "        col_sum = col_sum + H[j,i]\n",
    "    if col_sum == 0:\n",
    "        d[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Calculating the Influence Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21428571],\n",
       "       [0.14285714],\n",
       "       [0.35714286],\n",
       "       [0.07142857],\n",
       "       [0.14285714],\n",
       "       [0.07142857]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([3.0,2,5,1,2,1])\n",
    "A_tot = np.sum(a)\n",
    "a = a/A_tot\n",
    "a = a.reshape(6,1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16666667],\n",
       "       [0.16666667],\n",
       "       [0.16666667],\n",
       "       [0.16666667],\n",
       "       [0.16666667],\n",
       "       [0.16666667]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_0 = np.full((6, 1), 1/6)\n",
    "pi_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alp = 0.85\n",
    "eps = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eT = np.full((1, 6), 1)\n",
    "eT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.21428571, 0.28571429, 0.        , 0.8       ,\n",
       "        0.5       ],\n",
       "       [0.23076923, 0.14285714, 0.14285714, 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.15384615, 0.35714286, 0.        , 0.        , 0.2       ,\n",
       "        0.        ],\n",
       "       [0.        , 0.07142857, 0.14285714, 0.        , 0.        ,\n",
       "        0.16666667],\n",
       "       [0.61538462, 0.14285714, 0.42857143, 0.        , 0.        ,\n",
       "        0.33333333],\n",
       "       [0.        , 0.07142857, 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_prime = H.copy()\n",
    "for i in range(len(d)):\n",
    "    if d[i] == 1:\n",
    "        H_prime[:,i] = a.reshape(6,)\n",
    "H_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P = alp*H_prime + (1-alp)*a@eT\n",
    "#P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.30402138],\n",
       "       [0.16360304],\n",
       "       [0.18979616],\n",
       "       [0.04661906],\n",
       "       [0.27531309],\n",
       "       [0.02064727]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the influence vector\n",
    "pi_star_k1 = pi_0\n",
    "for i in range(100):\n",
    "    pi_star_k2 = alp*H@pi_star_k1+(alp*d@pi_star_k1+(1-alp))*a\n",
    "    if sum(np.abs(pi_star_k2-pi_star_k1)) < eps:\n",
    "        print(i)\n",
    "        break\n",
    "    pi_star_k1 = pi_star_k2\n",
    "pi_star_k2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Calculating Eigenfactor (EFi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34.05100649],\n",
       "       [17.20374224],\n",
       "       [12.17545523],\n",
       "       [ 3.6531636 ],\n",
       "       [32.91663244],\n",
       "       [ 0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Calculating Eigenfactor\n",
    "EF = 100*H@pi_star_k2/sum(H@pi_star_k2)\n",
    "EF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating Eigenfactor Scores function\n",
    "def cal_es(Z):    \n",
    "    # Set diagonal equals to zero\n",
    "    for i in range(len(Z)):\n",
    "        Z[i,i] = 0\n",
    "        \n",
    "    # nomalize\n",
    "    H = Z.copy()\n",
    "    col_sums = []\n",
    "    for i in range(len(H[0])):\n",
    "        col_sum = 0\n",
    "        for j in range(len(H)):\n",
    "            col_sum = col_sum + H[j,i]\n",
    "        col_sums = col_sums + [col_sum]\n",
    "        if col_sum != 0:\n",
    "            for k in range(len(H)):\n",
    "                H[k,i] = H[k,i]/col_sum\n",
    "            \n",
    "    # Create d(N times)\n",
    "    d = [0 if x != 0 else 1 for x in col_sums]\n",
    "    d = np.array(d)\n",
    "    \n",
    "    # Calculating the influecne factor\n",
    "    # A_tot\n",
    "    a = np.full((len(H[0]), 1), 1)\n",
    "    a = a/len(H[0])\n",
    "    a = a.reshape(len(H[0]),1)\n",
    "    \n",
    "    #pi_0\n",
    "    pi_0 = np.full((len(H[0]), 1), 1/len(H[0]))\n",
    "    \n",
    "    alp = 0.85\n",
    "    eps = 0.00001\n",
    "    \n",
    "    #eT\n",
    "    eT = np.full((1,len(H[0])), 1)\n",
    "    \n",
    "    # Compute the influence vector\n",
    "    pi_star_k = pi_0\n",
    "    for i in range(100):\n",
    "        pi_star_k1 = alp*H@pi_star_k+(alp*(d@pi_star_k)+(1-alp))*a\n",
    "        diff = np.sum(np.abs(pi_star_k1-pi_star_k))\n",
    "        if diff < eps:\n",
    "            break\n",
    "        pi_star_k = pi_star_k1\n",
    "    \n",
    "    #  Calculating Eigenfactor\n",
    "    EF = 100*H@pi_star_k1/(H@pi_star_k1).sum()\n",
    "    journal_index = list(range(len(Z)))\n",
    "    EF = pd.DataFrame(data=EF, index = journal_index)\n",
    "    \n",
    "    # Retrun EF and the number of iterations.\n",
    "    return EF,i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "110.72124361991882\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4408</th>\n",
       "      <td>1.448119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>1.412719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6610</th>\n",
       "      <td>1.235035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>0.679502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6919</th>\n",
       "      <td>0.664879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6667</th>\n",
       "      <td>0.634635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4024</th>\n",
       "      <td>0.577233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6523</th>\n",
       "      <td>0.480815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8930</th>\n",
       "      <td>0.477773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6857</th>\n",
       "      <td>0.439735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5966</th>\n",
       "      <td>0.429718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.386207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>0.385120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480</th>\n",
       "      <td>0.379578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.372789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>0.330306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>0.327508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6569</th>\n",
       "      <td>0.319272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5035</th>\n",
       "      <td>0.316779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.311257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "4408  1.448119\n",
       "4801  1.412719\n",
       "6610  1.235035\n",
       "2056  0.679502\n",
       "6919  0.664879\n",
       "6667  0.634635\n",
       "4024  0.577233\n",
       "6523  0.480815\n",
       "8930  0.477773\n",
       "6857  0.439735\n",
       "5966  0.429718\n",
       "1995  0.386207\n",
       "1935  0.385120\n",
       "3480  0.379578\n",
       "4598  0.372789\n",
       "2880  0.330306\n",
       "3314  0.327508\n",
       "6569  0.319272\n",
       "5035  0.316779\n",
       "1212  0.311257"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import files\n",
    "with open('links.txt', 'r') as f:\n",
    "    data = [[int(num) for num in line.split(',')] for line in f]\n",
    "\n",
    "start = time.time()    \n",
    "# change list to numpy array\n",
    "data = np.array(data)\n",
    "\n",
    "# combine all journals\n",
    "citing_cited = np.concatenate([data[:,0], data[:,1]])\n",
    "\n",
    "# make adjacency matrix\n",
    "Z = np.empty([len(np.unique(citing_cited)), len(np.unique(citing_cited))])\n",
    "for i in range(len(data)):\n",
    "    col = data[i,0]\n",
    "    row = data[i,1]\n",
    "    times = data[i,2]\n",
    "    Z[row,col] = times\n",
    "\n",
    "# calculating Eigenfactor\n",
    "result = cal_es(Z)\n",
    "\n",
    "# print results\n",
    "print(result[1])\n",
    "EF = result[0]\n",
    "stop = time.time()-start\n",
    "print(stop)\n",
    "EF.sort_values(0,ascending=False).iloc[0:20,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) The scores of the top 20 journals are on the above chart. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) The time of this alogrithm for this dataset is around 2 minutes(from constrcuting the adjacency matrix to calculate the result)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)  It tooks 31 iterations to get to my answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are my scratch code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.array([[1.0,0,2,0,4,3],[3,0,1,1,0,0],[2,0,4,0,1,0],\n",
    "              [0,0,1,0,0,1],[8,0,3,0,5,2],[0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((Z,Z),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "six = pd.DataFrame(data=Z)\n",
    "result = cal_es(six)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating Eigenfactor Scores function, df contains a N*N matrix\n",
    "def cal_es(df):\n",
    "    start = time.time()\n",
    "    Z = df.copy()\n",
    "    \n",
    "    # Set diagonal equals to zero(N times)\n",
    "    for i in range(len(Z)):\n",
    "        Z.iloc[i,i] = 0\n",
    "        \n",
    "    # nomalize(N times)\n",
    "    H = Z.copy()\n",
    "    col_sums = H.sum(axis=0)\n",
    "    for i in range(len(H[0])):\n",
    "        if(col_sums.iloc[i]!=0):\n",
    "            H.iloc[:,i] = H.iloc[:,i]/col_sums.iloc[i]\n",
    "            \n",
    "    # Create d(N times)\n",
    "    d = np.zeros(len(H[0]))\n",
    "    for i in range(len(H[0])):\n",
    "        if(col_sums.iloc[i]==0):\n",
    "            d[i] = 1\n",
    "            \n",
    "    # Calculating the influecne factor\n",
    "    # A_tot\n",
    "    a = np.full((len(H[0]), 1), 1)\n",
    "    a = a/len(H[0])\n",
    "    a = a.reshape(len(H[0]),1)\n",
    "    \n",
    "    #pi_0\n",
    "    pi_0 = np.full((len(H[0]), 1), 1/len(H[0]))\n",
    "    \n",
    "    alp = 0.85\n",
    "    eps = 0.00001\n",
    "    \n",
    "    #eT\n",
    "    eT = np.full((1,len(H[0])), 1)\n",
    "    \n",
    "    # Compute the influence vector\n",
    "    pi_star_k = pi_0\n",
    "    for i in range(100):\n",
    "        pi_star_k1 = alp*H@pi_star_k+(alp*(d@pi_star_k)+(1-alp))[0]*a\n",
    "        diff = np.sum(np.abs(pi_star_k1-pi_star_k)).iloc[0]\n",
    "        if diff < eps:\n",
    "            break\n",
    "        pi_star_k = pi_star_k1\n",
    "    \n",
    "    #  Calculating Eigenfactor\n",
    "    EF = 100*H@pi_star_k1/(H@pi_star_k1).sum()\n",
    "    stop = time.time()-start\n",
    "    \n",
    "    # Retrun EF, time and the number of iterations.\n",
    "    return EF,stop,i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run using function\n",
    "data = pd.read_csv('links.txt', sep=\",\", header=None)\n",
    "data.columns = [\"citing\", \"cited\", \"times\"]\n",
    "\n",
    "# Find all unique journals\n",
    "all_journal = pd.concat([data.citing, data.cited], axis=0)\n",
    "all_journal.nunique()\n",
    "\n",
    "# Creating dataframes with the number of journal as name of the index and column\n",
    "Z = np.empty([10748,10748])\n",
    "df = pd.DataFrame(data=Z, columns = all_journal.unique(), index = all_journal.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframes with the number of journal as name of the index and column\n",
    "start = time.time()\n",
    "for i in range(len(data)):\n",
    "    df.loc[data.loc[i,\"cited\"],data.loc[i,\"citing\"]] = data.loc[i,\"times\"]\n",
    "stop = time.time()-start\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('links.txt', sep=\",\", header=None)\n",
    "data.columns = [\"citing\", \"cited\", \"times\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(len(data)):\n",
    "    df.loc[data.loc[i,\"cited\"],data.loc[i,\"citing\"]] = data.loc[i,\"times\"]\n",
    "stop = time.time()-start\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cal_es(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[1])\n",
    "EF = result[0]\n",
    "EF = EF[0]\n",
    "descending_EF = EF.sort_values(ascending=False)\n",
    "print(descending_EF.iloc[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all unique journals\n",
    "all_journal = pd.concat([data.citing, data.cited], axis=0)\n",
    "all_journal.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframes with the number of journal as name of the index and column\n",
    "Z = np.empty([10748,10748])\n",
    "df = pd.DataFrame(data=Z, columns = all_journal.unique(), index = all_journal.unique())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter txt files to the dataframe\n",
    "for i in range(len(data)):\n",
    "    df.loc[data.loc[i,\"cited\"],data.loc[i,\"citing\"]] = data.loc[i,\"times\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = df.copy()\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set diagonal equal to 0\n",
    "for i in range(len(Z)):\n",
    "    Z.iloc[i,i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomalize\n",
    "H = Z.copy()\n",
    "col_sums = H.sum(axis=0)\n",
    "for i in range(len(H[0])):\n",
    "    if(col_sums.iloc[i]!=0):\n",
    "        H.iloc[:,i] = H.iloc[:,i]/col_sums.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create d\n",
    "d = np.zeros(len(H[0]))\n",
    "for i in range(len(H[0])):\n",
    "    if(col_sums.iloc[i]==0):\n",
    "        d[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the influecne factor\n",
    "# A_tot\n",
    "A_tot = np.full((len(H[0]), 1), 1)\n",
    "A_tot = A_tot/len(H[0])\n",
    "A_tot = A_tot.reshape(len(H[0]),1)\n",
    "A_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pi_0\n",
    "pi_0 = np.full((len(H[0]), 1), 1/len(H[0]))\n",
    "pi_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alp = 0.85\n",
    "eps = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eT\n",
    "eT = np.full((1,len(H[0])), 1)\n",
    "eT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making H_prime\n",
    "H_prime = H.copy()\n",
    "for i in range(len(d)):\n",
    "    if d[i] == 1:\n",
    "        H_prime.iloc[:,i] = A_tot.reshape(len(H[0]),)\n",
    "H_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P\n",
    "P = alp*H_prime + (1-alp)*A_tot@eT\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute leading eigenvector\n",
    "pi_star = pi_0\n",
    "for i in range(100):\n",
    "    pi_star = alp*H@pi_star+(alp*(d@pi_star)[0]+(1-alp))*A_tot\n",
    "pi_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EF = 100*H@pi_star/(H@pi_star).sum()\n",
    "EF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
